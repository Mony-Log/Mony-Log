{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import TYPE_CHECKING\n",
    "from pydantic import SecretStr\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from schema import ResultSchema, LangchainLLMExpenseAnalyzeResult, LangchainLLMExpenseAnalyzerConfig\n",
    "from prompt import __PROMPT_TEMPLATE__\n",
    "from pendulum import DateTime\n",
    "from uuid import uuid4\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from langchain_core.runnables import RunnableSerializable\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LangchainLLMExpenseAnalyzePipeline:\n",
    "    \"\"\"\n",
    "    A generic pipeline for analyzing expenses using Langchain LLM.\n",
    "    This class is a placeholder for the actual implementation.\n",
    "    \"\"\"\n",
    "\n",
    "    config: LangchainLLMExpenseAnalyzerConfig | dict = field(default_factory=LangchainLLMExpenseAnalyzerConfig)\n",
    "    client: ChatOpenAI = field(init=False, repr=False)\n",
    "    pipeline: \"RunnableSerializable\" = field(init=False, repr=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        if isinstance(self.config, dict):\n",
    "            self.config = LangchainLLMExpenseAnalyzerConfig(**self.config)\n",
    "        self.client = ChatOpenAI(**self.config.model_dump())\n",
    "        self.client = self.client.with_structured_output(schema=ResultSchema, include_raw=True, strict=True)  # type: ignore\n",
    "        self.pipeline = __PROMPT_TEMPLATE__ | self.client | self.__output_processe\n",
    "\n",
    "    def __output_processe(self, response: dict) -> LangchainLLMExpenseAnalyzeResult:\n",
    "        return LangchainLLMExpenseAnalyzeResult(\n",
    "            id=response[\"raw\"].id,  # type: ignore\n",
    "            message=response[\"raw\"].content,  # type: ignore\n",
    "            expenses=response[\"parsed\"].expenses,  # type: ignore\n",
    "        )\n",
    "\n",
    "    async def aanalyze(\n",
    "        self,\n",
    "        message: str,\n",
    "        tags: list[str],\n",
    "        current_datetime=DateTime.now(\"Asia/Seoul\").to_iso8601_string(),\n",
    "        config: dict | None = None,\n",
    "    ) -> LangchainLLMExpenseAnalyzeResult:\n",
    "        response = await self.pipeline.ainvoke(\n",
    "            dict(\n",
    "                current_datetime=current_datetime,\n",
    "                message=message,\n",
    "                tags=tags,\n",
    "            ),\n",
    "            config=config,\n",
    "        )\n",
    "        response.message = message.strip()\n",
    "        return response\n",
    "\n",
    "    def analyze(\n",
    "        self,\n",
    "        message: str,\n",
    "        tags: list[str],\n",
    "        current_datetime=DateTime.now(\"Asia/Seoul\").to_iso8601_string(),\n",
    "        config: dict | None = None,\n",
    "    ) -> LangchainLLMExpenseAnalyzeResult:\n",
    "        response = self.pipeline.invoke(\n",
    "            dict(\n",
    "                current_datetime=current_datetime,\n",
    "                message=message,\n",
    "                tags=tags,\n",
    "            ),\n",
    "            config=config,\n",
    "        )\n",
    "        response.message = message.strip()\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81780959",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = LangchainLLMExpenseAnalyzePipeline(\n",
    "    config=dict(\n",
    "        base_url=\"http://localhost:1234/v1\",\n",
    "        api_key=\"lm-studio\",\n",
    "        model=\"qwen2.5-vl-7b-instruct\",\n",
    "        temperature=0.0,\n",
    "        max_tokens=1024 * 2,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2877f7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = \"담배값 2만원, 점심비용 1.5만원, 저녁 비용 2.3만원\"\n",
    "tags = [\"담배\", \"커피\", \"편의점\", \"식비\", \"데이트\", \"교육\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a934697",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pipeline.analyze(message=message, tags=tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cdbc8fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expense-담배값-20000-[['담배']]\n",
      "Expense-점심비용-15000-[['식비']]\n",
      "Expense-저녁 비용-23000-[['식비']]\n"
     ]
    }
   ],
   "source": [
    "for e in results.expenses:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff277fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
